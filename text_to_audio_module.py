#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡ç”ŸéŸ³é¢‘åŠŸèƒ½æ¨¡å—
åŒ…å«UIç•Œé¢å’Œä¸šåŠ¡é€»è¾‘
"""

import gradio as gr
import time
from vidu_client import ViduClient, ViduAudioModel, ViduTaskStatus
from utils import get_error_message


def create_text_to_audio_task(client: ViduClient, model: str, prompt: str, duration: float, seed: int) -> str:
    """åˆ›å»ºæ–‡ç”ŸéŸ³é¢‘ä»»åŠ¡å¹¶è½®è¯¢ç»“æœ"""
    try:
        if not prompt.strip():
            return "âŒ è¯·è¾“å…¥æ–‡æœ¬æç¤ºè¯"
        
        # éªŒè¯æ—¶é•¿èŒƒå›´
        if duration < 2 or duration > 10:
            return "âŒ éŸ³é¢‘æ—¶é•¿å¿…é¡»åœ¨2-10ç§’ä¹‹é—´"
        
        # åˆ›å»ºä»»åŠ¡
        response = client.text_to_audio(
            model=model,
            prompt=prompt.strip(),
            duration=duration,
            seed=seed if seed != 0 else None
        )
        if not isinstance(response, dict) or 'task_id' not in response:
            return f"âŒ åˆ›å»ºä»»åŠ¡å¤±è´¥ï¼ŒAPIè¿”å›: {response}"
        task_id = response['task_id']
        
        # ç«‹å³æ˜¾ç¤ºä»»åŠ¡ID
        result = f"âœ… æ–‡ç”ŸéŸ³é¢‘ä»»åŠ¡åˆ›å»ºæˆåŠŸï¼<br>ä»»åŠ¡ID: {task_id}<br>"
        result += "â³ æ­£åœ¨ç­‰å¾…ä»»åŠ¡å®Œæˆ...<br>"
        
        start_time = time.time()
        while True:
            # æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
            task_info = client.query_task(task_id)
            if not isinstance(task_info, dict):
                return f"âŒ æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€å¤±è´¥: {task_info}"
            
            state = task_info.get('state')
            elapsed_time = int(time.time() - start_time)
            
            if state == ViduTaskStatus.SUCCESS:
                # ä»»åŠ¡å®Œæˆï¼Œæä¾›ä¸‹è½½é“¾æ¥
                result = f"âœ… æ–‡ç”ŸéŸ³é¢‘ä»»åŠ¡åˆ›å»ºæˆåŠŸï¼<br>ä»»åŠ¡ID: {task_id}<br>"
                result += f"âœ… ä»»åŠ¡å®Œæˆï¼è€—æ—¶: {elapsed_time}ç§’<br>"
                result += "ğŸ“¥ è¯·ç‚¹å‡»ä»¥ä¸‹é“¾æ¥ä¸‹è½½æ–‡ä»¶ï¼š<br><br>"
                
                # è·å–ä¸‹è½½é“¾æ¥
                try:
                    audio_url = client.get_audio_url(task_info)
                    if audio_url:
                        result += f"ğŸ”Š <a href='{audio_url}' target='_blank' style='color: #007bff; text-decoration: none;'>ç‚¹å‡»ä¸‹è½½éŸ³é¢‘</a><br><br>"
                except Exception as link_error:
                    result += f"âš ï¸ è·å–ä¸‹è½½é“¾æ¥å¤±è´¥: {str(link_error)}<br>"
                    result += "ğŸ’¡ è¯·ç¨åé‡è¯•æˆ–è”ç³»æŠ€æœ¯æ”¯æŒ<br>"
                break
            elif state == ViduTaskStatus.FAILED:
                err_code = task_info.get('err_code', 'æœªçŸ¥é”™è¯¯')
                result = f"âœ… æ–‡ç”ŸéŸ³é¢‘ä»»åŠ¡åˆ›å»ºæˆåŠŸï¼<br>ä»»åŠ¡ID: {task_id}<br>"
                result += f"âŒ ä»»åŠ¡å¤±è´¥: {get_error_message(err_code)}<br>"
                break
            elif state in [ViduTaskStatus.CREATED, ViduTaskStatus.QUEUEING, ViduTaskStatus.PROCESSING]:
                # æ›´æ–°ç­‰å¾…æ—¶é—´
                result = f"âœ… æ–‡ç”ŸéŸ³é¢‘ä»»åŠ¡åˆ›å»ºæˆåŠŸï¼<br>ä»»åŠ¡ID: {task_id}<br>"
                result += f"â³ æ­£åœ¨ç­‰å¾…ä»»åŠ¡å®Œæˆ... å·²ç­‰å¾…: {elapsed_time}ç§’<br>"
                time.sleep(1)  # ç­‰å¾…1ç§’
            else:
                result = f"âœ… æ–‡ç”ŸéŸ³é¢‘ä»»åŠ¡åˆ›å»ºæˆåŠŸï¼<br>ä»»åŠ¡ID: {task_id}<br>"
                result += f"âŒ æœªçŸ¥ä»»åŠ¡çŠ¶æ€: {state}<br>"
                break
        
        return result
        
    except Exception as e:
        return f"âŒ åˆ›å»ºä»»åŠ¡å¤±è´¥: {str(e)}"


def create_text_to_audio_ui(client: ViduClient):
    """åˆ›å»ºæ–‡ç”ŸéŸ³é¢‘UIç•Œé¢"""
    with gr.Tab("ğŸµ æ–‡ç”ŸéŸ³é¢‘"):
        with gr.Row():
            text2audio_model = gr.Dropdown(
                choices=["audio1.0"],  # æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œåªæœ‰audio1.0æ¨¡å‹
                value="audio1.0",
                label="éŸ³é¢‘æ¨¡å‹"
            )
        
        text2audio_prompt = gr.Textbox(
            label="æ–‡æœ¬æç¤ºè¯",
            placeholder="è¯·è¾“å…¥è¦è½¬æ¢ä¸ºéŸ³é¢‘çš„æ–‡æœ¬æè¿°ï¼Œä¾‹å¦‚ï¼šæ¸…æ™¨çš„é¸Ÿå«å£°...",
            lines=5
        )
        
        with gr.Row():
            text2audio_duration = gr.Slider(
                minimum=2.0,
                maximum=10.0,
                value=10.0,
                step=0.5,
                label="éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰",
                info="å¯é€‰èŒƒå›´ï¼š2-10ç§’ï¼Œé»˜è®¤10ç§’"
            )
            text2audio_seed = gr.Number(
                value=0,
                label="éšæœºç§å­",
                info="0è¡¨ç¤ºè‡ªåŠ¨ç”Ÿæˆï¼Œå›ºå®šå€¼ç”Ÿæˆç¡®å®šæ€§ç»“æœ"
            )
        
        text2audio_btn = gr.Button("åˆ›å»ºæ–‡ç”ŸéŸ³é¢‘ä»»åŠ¡", variant="primary")
        text2audio_status = gr.HTML(label="çŠ¶æ€", visible=False)
        text2audio_output = gr.HTML(label="ä»»åŠ¡ç»“æœ")
        
        def text2audio_task(model, prompt, duration, seed):
            return (
                gr.HTML(value="<div style='color: #007bff; font-weight: bold;'>â³ ç”Ÿæˆä¸­ï¼Œè¯·è€å¿ƒç­‰å¾…...</div>", visible=True),
                gr.HTML(value=""),
                gr.Button(interactive=False),
                gr.Dropdown(interactive=False),
                gr.Textbox(interactive=False),
                gr.Slider(interactive=False),
                gr.Number(interactive=False)
            )
        
        def text2audio_complete(result):
            return (
                gr.HTML(visible=False),
                gr.HTML(value=result),
                gr.Button(interactive=True),
                gr.Dropdown(interactive=True),
                gr.Textbox(interactive=True),
                gr.Slider(interactive=True),
                gr.Number(interactive=True)
            )
        
        text2audio_btn.click(
            fn=text2audio_task,
            inputs=[text2audio_model, text2audio_prompt, text2audio_duration, text2audio_seed],
            outputs=[text2audio_status, text2audio_output, text2audio_btn, text2audio_model,
                   text2audio_prompt, text2audio_duration, text2audio_seed],
            queue=False
        ).then(
            fn=lambda *args: create_text_to_audio_task(client, *args),
            inputs=[text2audio_model, text2audio_prompt, text2audio_duration, text2audio_seed],
            outputs=[text2audio_output]
        ).then(
            fn=text2audio_complete,
            inputs=[text2audio_output],
            outputs=[text2audio_status, text2audio_output, text2audio_btn, text2audio_model,
                   text2audio_prompt, text2audio_duration, text2audio_seed]
        )
        
        return {
            'model': text2audio_model,
            'prompt': text2audio_prompt,
            'duration': text2audio_duration,
            'seed': text2audio_seed,
            'btn': text2audio_btn,
            'status': text2audio_status,
            'output': text2audio_output
        } 